== Video Scripts for Applied Graph Algorithms Training

=== Intro Video (TBD - Will create at the end, if we think it's needed)

==== Goals
==== Algorithm Buckets 
==== Structure of Training
==== Getting Help

=== Part 1: Category Hierarchy Video
* Now that we've explored the Yelp data a bit, we're going to take a deeper look at business categories. 

==== Problem Situation
{Screenshot from the first category example}

* Some of you may have noticed that there are many business categories in Yelp that seem related but aren't organized together. For example, we can safely assume some similar menu items or food styles between a business categorized as a sushi bar and another one as a ramen shop.
{Visual of sushi - ramen}

* We can imagine how being able to group similar businesses is essential to certain types of analysis such as finding general preferences. But it's also essential for creating intuitive navigation between types of business. 
* Our challenge in this section is to take a list of a 100 random business categories and automatically create a taxonomy that's easier for users to traverse.
{Fade back to first screenshot example with "100" and graphy steps}

* Since it would be tedious to do this manually on even a small dataset, we want to learn the structure and hierarchy of business categories that are already hiding in the Yelp data, using a graph algorithm.

==== Algorithm: Overlap Similarity
* The Overlap Similarity algorithm is the perfect choice when we're trying to find the hierarchy in data and develop super and sub-categories. This is related to how it measures the overlap between two groups of nodes.  
* The algorithm provides a similarity coefficient that represents the co-occurrence of items between those groups. 
{Visual of the Formula with A and B}

* Mathematically, the coefficient is defined as the intersection divided by the smaller of the two groups.  
{Visual of the circles - animate below}

* For example, if set A contains {Orange, Blue, Green} and set B contains {Orange, Blue, Purple, Black} then the overlap algorithm counts 2 co-occurrences {Cyan, Blue} and divides that count by the number of items in the smallest set, in this case, 3.  The resulting overlap coefficient is 2/3 which is 0.66.
* If A contains {Orange, Blue, PURPLE} then the overlap coefficient would be 1.
* A coefficient of 1 indicates that either the groups are identical or more likely, that one is a subgroup of the other. 
{Visual of the circles but now completely overlap. Animate?}

* Although the Overlap Similarity algorithm is also used to evaluate general similarities its use of the smaller set as a denominator makes its ideal for extracting subgroups. 
** Identification of multiple subgroups is an effective way to develop taxonomies.  

==== Tips / Warnings?
* During the excercise, you may find bla blah [*Mark / Will* Maybe we add once we're almost done?] 
* If you get stuck, you can always refer to our documentation:
** On the developers guide - https://neo4j.com/docs/developer-manual/current/ 
** On the Overlap Similarity Algorithm - https://neo4j.com/docs/graph-algorithms/3.4/algorithms/similarity-overlap/
* Also, please feel free to ask for help on our Community Forum https://community.neo4j.com/c/general/online-training 

==== At The End of This Part
* By the end of this section we will have updated the user navigation to reflect top-level categorizations of Yelp businesses.
* There will be a short quiz to evalute progress.
* You should be able to explain what the overlap coefficient represents and be familiar with using a NARROWER_THAN relationship to build a taxonomy.


=== Part 2: Ordering search results
* Now that we've have a good navigation for users that next thing we'd like to do is show more relevant information to our users.

==== Problem Situation 
* Like so many reviews sites, there is a lot of information in Yelp to sift through. It would be best to develop a way to show users information that's most relevant to them personally.
* For example, instead of selecting the reviews for businesses based on the opinions of reviwers unrelated to the users, we want to show reviews written by someone similar. 
* Our challenge in this section is to order reviews in a search result by the reviewers most like the user. Then we'll update the application to use this new information.

==== Algorithm: Pearson Smiliarity
* The Pearson Smiliarity algorithm is widely used to compute how strongly two things are related, or rather correlated. It is particularly well-suited for recommendations based on user ratings because it takes into account the fact that different users will have different mean ratings.
** On average some users will tend to give higher ratings than others. 
** Since Pearson similarity considers differences in the mean, it account for these types of discrepancies.
* The algorithm computes a similarity coefficient that measures the linear correlation between two variables, say A and B.
{Algorithm visual - add in what each items means. Animate red circles to relate to below talking points.}

* In this formula, our raw observations are centered by subtracting their means and then re-scaled by a measure of standard deviations. 
* Dividing the covariance between two variables by the product of standard deviations ensures that correlation will always fall between +1 and -1. This makes interpreting the correlation coefficient much easier and provides us both the magnitude and direction of correlation.
{3 Line graphs with some scores for below}

** The closer Peason's correlation coefficient is to +1, the more an increase in one variable associates with an increase in the other. (We can see this as a positive correlation or direction.) 
** On the other hand, the closer to -1, the increase in one variable would result in decrease in the other. (We'd call this a negative correlation or direction.) 
** At 0 there is no linear correlation, which means the variables are completely independent 
** Note that a Pearson's correlation number does not equate to the slope between A and B.
{Fade back to algorithm}

* There are 2 caveats worth mentioning when using Pearson's similarity.
** If we look at the formula once again, you might be able to see where it could be sensitive to the influence of extreme outlier data points that pull the mean in one direction or another. If we get unexpected results using this algorithm, this is one area to check. 
** It's also worth noting that there is no implied causual direction in Pearson's. While this is not unique, I feel it's always good noting that correlation does not equal causation when presenting these types of results.  
{XKCD - Cancer causes Cell Phones}

==== Tips / Warnings?  
* During the excercise, you may find bla blah [*Mark / Will* Maybe we add once we're almost done?] 
* If you get stuck, you can always refer to our documentation:
** On the developers guide - https://neo4j.com/docs/developer-manual/current/ 
** On the Pearson Similarity Algorithm - https://neo4j.com/docs/graph-algorithms/3.4/algorithms/SOMETHING
* Also, please feel free to ask for help on our Community Forum https://community.neo4j.com/c/general/online-training 

==== At The End of This Part
* By the end of this section we will have updated our app so the user search results are ordered so that the reviews of more similiar reviewers are shown at top.
* There will be a short quiz to evalute progress.
* You should be able to explain what the Pearson similarity algorithm is used for and what the direction and magnitude of the correlation coefficiant represents. 
* You should also be familiar with how to set basic parameter such as a cut-off value.


=== Part 3: Most relevant reviews
==== Problem Situation
* By now we've improved our app to be easier to navigate and ordered reviews by people who tend to rate things the way the user does. But there's more we can do to bubble up the businesses we think the user will like, as a form of recommendation.
* Our challenge in this section will be to show business results based on the positive reviews of influential users in the Yelp network. 
** Influential reviewers tend to be predictive of which businsses will be reviewed by others, which we're using as a stand in for predicting becoming a customer.
* Also, as opposed to looking at all possible influential reviewers we only want to take into account those that are closer to our user in the network. 

==== Algorithm: PPR
* The Personalized PageRank algorithm is a variation of PageRank that is handy for recommendations. But let's start with PageRank itself, which is probably the best known centrality algorithms
* PageRank measures the transitive (or directional) influence of nodes and considers the influence of your neighbors and their neighbors. 
* An example of this type of influence might be having the ear of a general that considers you very credible will likely make you more powerful than being really popular with your fellow foot soldiers. 
* PageRank measure importance in comparision to other nodes using an iterative process to update ranks.
{Triangle Picture}
* It starts by assigning values to nodes as 1/n (n is the total number of nodes linked to) and value to relationships as that nodes value / # of it's outgoing links. 
* It then starts to update values for nodes as the sum of the prior in-link values. The relationship values are updated the same way they were initially assigned. 
* PageRank then continues to update values until an iterate value is reached. 
{Formula with elements defined}
* In the formula for PageRank, T1...Tn are the nodes with incomming links to u. We can see that the value of those nodes are divided by C - the parameter their own outgoing links.
* A dampending factor, d, is added to help keep PR from getting dragged down into loops and tangents (and deadends). The dampending factor is the probably that the next step of the algorithm will follow a direct path. It's basically the opposite of a random skip to another node. 
* For example, the standard dampening of 0.85 means on each next caluclation there is a 15% chance the algorithm will look at a random node, not directly connected to where it is at that moment. 
* The dampending factor is how Personalized PageRank becomes, well, personalized. You see, intead of randomly skipping to node in the graph, in PPR, it will hop back to a particular set of nodes you identify.  This give us a look at the influence in the graph that's never too far way from our starting point. 
* And of course, we can tailor our results by changing the dampending factor and the number of SourceNodes.
{picture ?}
* So we can see why PPR is particuliarly useful where you're looking for influential elements in an area surrounding a node. 
* This approach is different from similarity algorithms that look for how common nodes of the same type are.
* It's also different than community detection algorithms that are looking for groupings. 

==== Tips / Warnings? 
* During the excercise, you may find bla blah [*Mark / Will* Maybe we add once we're almost done?] 
* If you get stuck, you can always refer to our documentation:
** On the developers guide - https://neo4j.com/docs/developer-manual/current/ 
** On the Personalized PageRank Algorithm - https://neo4j.com/docs/graph-algorithms/3.4/algorithms/page-rank/
* Also, please feel free to ask for help on our Community Forum https://community.neo4j.com/c/general/online-training 

==== At The End of This Part
* By the end of this section we will have
//updated the user navigation to reflect top-level categorizations of Yelp businesses.--
* There will be a short quiz to evalute progress.
* You should be able to
//explain what the overlap coefficient represents and be familiar with using a NARROWER_THAN relationship to build a taxonomy.


=== Part 4: Photo based gallery recomendations

==== Problem Situation
==== Algorithm: LPA
==== Tips / Warnings? 
* During the excercise, you may find bla blah [*Mark / Will* Maybe we add once we're almost done?] 
* If you get stuck, you can always refer to our documentation:
** On the developers guide - https://neo4j.com/docs/developer-manual/current/ 
** On the Label Propagation Algorithm - https://neo4j.com/docs/graph-algorithms/3.4/algorithms/label-propagation/
* Also, please feel free to ask for help on our Community Forum https://community.neo4j.com/c/general/online-training 

==== At The End of This Part
* By the end of this section we will have
//updated the user navigation to reflect top-level categorizations of Yelp businesses.--
* There will be a short quiz to evalute progress.
* You should be able to
//explain what the overlap coefficient represents and be familiar with using a NARROWER_THAN relationship to build a taxonomy.
